import java.io.BufferedReader;
import java.io.FileReader;
import java.net.URI;
import java.util.HashMap;
import java.util.Map;

import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;


public class MyDC {

	public static class MyMapper extends Mapper<LongWritable, Text, Text, Text> {
		
		private Map<String, String> abMap = new HashMap<String, String>();
		private Map<String, String> abMap1 = new HashMap<String, String>();
		private Text outputKey = new Text();
		private Text outputValue = new Text();
		
		protected void setup(Context context)
		
		super.setup(context);
		URI[] files = context.getCacheFiles();
		
		Path p = new Path(files[0]);
		
		Path p1 = new Path(files[1]);
		
		if (p.getName().equals("salary.txt")){
			BufferedReader reader = new BufferedReader(new FileReader(p.toString()));
			String line = reader.readLine();
			while(line != null){
				String[] tokens = line.split(",");
				String emp_id = tokens[0];
				String emp_sal = tokens[1];
				abMap.put(emp_id,emp_sal);
				line = reader.readLine();
				
			}
			reader.close();
		}
		if (p1.getName().equals("desig.txt")){
			BufferedReader reader = new BufferedReader(new FileReader(p.toString()));
			while(line != null){
				String[] tokens = line.split(",");
				String emp_id = tokens[0];
				String emp_desig = tokens[1];
				abMap1.put(emp_id,emp_desig);
				line = reader.readLine();
				
			}
			
		}
	}
}

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;

import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;



public class Reducejoin {
	public static class CustsMapper extends Mapper<LongWritable, Text, Text, Text>{
		
		public void map(LongWritable inpKey, Text value, Context context) throws IOException, InterruptedException{
			String record = value.toString();
			String[] parts = record.split(",");
			 context.write(new Text(parts[0]).new Text("custs\t" + parts[1]));
			 
			 
		 }
			
	}
	 public static class TxnsMapper extends Mapper<LongWritable, Text, Text, Text> {
		 
		 public void map(LongWritable key,Text value,Context context) throws IOException, InterruptedException{
			 String record = value.toString();
				String[] parts = record.split(",");
				 context.write(new Text(parts[2]).new Text("txns\t" + parts[3]));
				 
		 }
}
public static class ReduceJoinReducer extends Reducer<Text, Text, Text, Text>{
	public void reduce(Text key, Iterable<Text> values,Context context) throws IOException, InterruptedException{
		 String name ="";
		 double total = 0.0;
		 int count = 0;
		 for (Text t : values){
			  String parts[] = t.toString().split("\t");
			  if (parts[0].equals("txns")){
				  count++;
				  total += Float.parseFloat(parts[1]);
			  }
			  else if (parts[0].equals("custs")){
				  name = parts[1];
			  }
		 }
		 String str = String.format("%d\t%f", count, total);
		 context.write(new Text(name), new Text(str));
	}}
		 public static void main(String[] args) throws Exception {
			    Configuration conf = new Configuration();
			    //conf.set("name", "value")
			    if(args.length > 2)
			    {
			    	conf.set("myText", args[2]) ;
			    }
			    
			    Job job = Job.getInstance(conf, "word Count");
			    job.setJarByClass(WordCount.class);
			    job.setMapperClass(.class);
			   //job.setCombinerClass(IntSumReducer.class);
			    job.setReducerClass(IntSumReducer.class);
			    //job.setNumReduceTasks(0);
			    job.setOutputKeyClass(Text.class);
			    job.setOutputValueClass(IntWritable.class);
			    FileInputFormat.addInputPath(job, new Path(args[0]));
			    FileOutputFormat.setOutputPath(job, new Path(args[1]));
			    System.exit(job.waitForCompletion(true) ? 0 : 1);
			  }

		}

			   	
